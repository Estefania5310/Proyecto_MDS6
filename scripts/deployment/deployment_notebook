{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1753393517312,"user":{"displayName":"Daniel Tejada Hernandez","userId":"08292253613217380086"},"user_tz":300},"id":"ALOWMzaQAmRQ"},"outputs":[],"source":["from IPython.display import display"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"g-jOtBX7_YD-","executionInfo":{"status":"ok","timestamp":1753393517331,"user_tz":300,"elapsed":30,"user":{"displayName":"Daniel Tejada Hernandez","userId":"08292253613217380086"}}},"outputs":[],"source":["from google.colab import userdata"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"CfvNaaCy0-En","executionInfo":{"status":"ok","timestamp":1753393517332,"user_tz":300,"elapsed":30,"user":{"displayName":"Daniel Tejada Hernandez","userId":"08292253613217380086"}}},"outputs":[],"source":["import os\n","from IPython import get_ipython\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from typing import Tuple, Dict, Any, Literal, Union\n","from pathlib import Path"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":116163,"status":"ok","timestamp":1753393517309,"user":{"displayName":"Daniel Tejada Hernandez","userId":"08292253613217380086"},"user_tz":300},"id":"2vajieNR0_9e","outputId":"de66b1f1-4082-4f30-a101-2da5b99d9a3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"BU1hlBA6jztU"},"source":["# Definición del path del proyecto"]},{"cell_type":"markdown","metadata":{"id":"q-wxFGXDOE0t"},"source":["Se interactua con la shell para configurar el correo electrónico, usuario global de Git, el nombre de usuario y la rama predeterminada para el repositorio. Esto es importante para atribuir las confirmaciones (commits) correctamente al interactuar con Git. Finalmente, se cambia el directorio de trabajo actual del notebook de Colab a `/content/drive/MyDrive/Proyecto_MDS6/`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":207,"status":"ok","timestamp":1753382369221,"user":{"displayName":"Daniel Tejada Hernandez","userId":"08292253613217380086"},"user_tz":300},"id":"EKxSHaCnmgON","outputId":"6eaf361c-5a4e-4f1c-9964-2d00118e5c7b"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/My Drive/Proyecto_MDS6\n","/content/drive/MyDrive\n","/content/drive/MyDrive\n"]}],"source":["!pwd\n","%cd /content/drive/MyDrive/\n","!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":108,"status":"ok","timestamp":1753382369327,"user":{"displayName":"Daniel Tejada Hernandez","userId":"08292253613217380086"},"user_tz":300},"id":"azCd0YBP_jTZ","outputId":"a1897a81-a27d-44eb-c6a3-25047b2ca6ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: destination path 'Proyecto_MDS6' already exists and is not an empty directory.\n"]}],"source":["!git clone https://github.com/Estefania5310/Proyecto_MDS6.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fQXie_Rz-4qN"},"outputs":[],"source":["#Identificacion cuenta github\n","!git config --global user.email \"dtejadah@unal.edu.co\"\n","!git config --global user.name \"biodani\"\n","!git config --global init.defaultBranch master"]},{"cell_type":"markdown","metadata":{"id":"Bpv5cJtqNrAF"},"source":["Esta celda usa función `userdata` del módulo `google.colab`. Esta función se utiliza para acceder de forma segura a los secretos almacenados en el gestor de secretos de Colab, como claves de API o tokens. En este caso se usa para mantener secreto el token de github."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VH0h1uXC_hoX"},"outputs":[],"source":["TOKEN_GITHUB = userdata.get('TOKEN_GITHUB')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":90,"status":"ok","timestamp":1753382370135,"user":{"displayName":"Daniel Tejada Hernandez","userId":"08292253613217380086"},"user_tz":300},"id":"K9xq12akj4OL","outputId":"73558335-1fc5-46c9-cfb4-986530e8651e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1753382370144,"user":{"displayName":"Daniel Tejada Hernandez","userId":"08292253613217380086"},"user_tz":300},"id":"H3u_1xNJ8PK_","outputId":"ecf18ee2-1e74-4469-f2e0-ab5edb05c650"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Proyecto_MDS6\n"]}],"source":["%cd  /content/drive/MyDrive/Proyecto_MDS6/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":143,"status":"ok","timestamp":1753382370286,"user":{"displayName":"Daniel Tejada Hernandez","userId":"08292253613217380086"},"user_tz":300},"id":"TNoeKSHgkbFb","outputId":"d60c14de-d5cd-45d6-b977-3e00af6c938e"},"outputs":[{"name":"stdout","output_type":"stream","text":["docs  pyproject.toml  README.md  scripts  src\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66,"status":"ok","timestamp":1753382370351,"user":{"displayName":"Daniel Tejada Hernandez","userId":"08292253613217380086"},"user_tz":300},"id":"lZWd_D9_JAjn","outputId":"52b9f4ae-d6e1-46ef-9dab-fa1387efccf2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reinitialized existing Git repository in /content/drive/MyDrive/Proyecto_MDS6/.git/\n"]}],"source":["!git init"]},{"cell_type":"markdown","metadata":{"id":"Ovcxs77nGKIR"},"source":["# Función de carga, preprocesamiento y data augmentation para los datos de entrenamiento"]},{"cell_type":"markdown","metadata":{"id":"GQINTSZhGnL5"},"source":["## Evaluación de la función de los datos de entrenamiento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v-gsYsqB0Mhr"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from typing import Tuple, Dict, Any, Literal, Union\n","from pathlib import Path\n","\n","def create_augmented_train_generator(\n","    data_directory: str,\n","    image_height: int,\n","    image_width: int,\n","    batch_size: int,\n","    class_mode: Literal['categorical', 'binary', 'sparse', 'input', 'multi_output', None] = 'categorical',\n","    augmentation_params: Dict[str, Any] | None = None\n",") -> tf.keras.preprocessing.image.DirectoryIterator:\n","    \"\"\"\n","    Crea un generador de datos de imágenes para el conjunto de entrenamiento con aumentación.\n","\n","    Utiliza `tf.keras.preprocessing.image.ImageDataGenerator` para cargar imágenes\n","    desde un directorio y aplicar transformaciones de aumentación de datos.\n","\n","    Args:\n","        data_directory (str): La ruta al directorio raíz que contiene las imágenes de entrenamiento,\n","                              organizadas en subdirectorios por clase.\n","        image_height (int): La altura deseada de las imágenes de salida en píxeles.\n","        image_width (int): El ancho deseado de las imágenes de salida en píxeles.\n","        batch_size (int): El número de imágenes por lote (batch) que generará el iterador.\n","        class_mode (Literal): El modo de clase para las etiquetas. Puede ser 'categorical',\n","                              'binary', 'sparse', 'input', 'multi_output', o None.\n","                              Por defecto es 'categorical'.\n","        augmentation_params (Dict[str, Any] | None, opcional): Un diccionario que contiene\n","                                    los parámetros para las transformaciones de aumentación de datos\n","                                    que se aplicarán (ej. 'rotation_range', 'zoom_range', etc.).\n","                                    Si es `None`, se utiliza un conjunto de parámetros predeterminado\n","                                    (similar al de tu ejemplo original). Por defecto es `None`.\n","\n","    Returns:\n","        tf.keras.preprocessing.image.DirectoryIterator: Un objeto iterador de Keras\n","                                                        que genera lotes de imágenes\n","                                                        y etiquetas aumentadas.\n","\n","    Raises:\n","        FileNotFoundError: Si el directorio de datos especificado no existe.\n","    \"\"\"\n","    # Verifica si el directorio existe\n","    if not Path(data_directory).is_dir():\n","        raise FileNotFoundError(f\"El directorio de datos de entrenamiento no existe: {data_directory}\")\n","\n","    # Parámetros de aumentación predeterminados si no se proporcionan\n","    if augmentation_params is None:\n","        augmentation_params = {\n","            'rotation_range': 20,\n","            'width_shift_range': 0.2,\n","            'height_shift_range': 0.2,\n","            'shear_range': 0.2,\n","            'zoom_range': 0.2,\n","            'horizontal_flip': True,\n","            'fill_mode': 'nearest'\n","        }\n","\n","    # Crear el ImageDataGenerator con reescalado y parámetros de aumentación\n","    data_generator = ImageDataGenerator(rescale=1./255, **augmentation_params)\n","\n","    print(f\"Creando generador de entrenamiento desde: {data_directory}\")\n","    print(f\"Tamaño de imagen: ({image_height}, {image_width}), Tamaño de lote: {batch_size}\")\n","    print(f\"Modo de clase: '{class_mode}'\")\n","    print(\"Parámetros de aumentación aplicados:\", augmentation_params)\n","\n","    # Crear el generador a partir del directorio\n","    generator = data_generator.flow_from_directory(\n","        directory=data_directory,\n","        target_size=(image_height, image_width),\n","        batch_size=batch_size,\n","        class_mode=class_mode\n","    )\n","\n","    print(f\"Generador de entrenamiento creado. Encontradas {generator.samples} imágenes pertenecientes a {generator.num_classes} clases.\")\n","\n","    return generator"]},{"cell_type":"markdown","metadata":{"id":"NuxvZ2diGxqw"},"source":["## Ejemplo de uso de la función de entrenamiento\n","\n","Esta celda es un ejemplo de cómo usar la función `create_augmented_train_generator`. Configura parámetros como el directorio de datos, el tamaño de la imagen, el tamaño del lote (batch) y los parámetros de aumentación, luego llama a la función e imprime información sobre el generador creado."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1753382370417,"user":{"displayName":"Daniel Tejada Hernandez","userId":"08292253613217380086"},"user_tz":300},"id":"2a_gpABz0OFj","outputId":"9af2306b-d46b-473f-ed39-df1c71ac6752"},"outputs":[{"name":"stdout","output_type":"stream","text":["Creando generador de entrenamiento desde: /content/drive/MyDrive/DL-Proyecto/Data/Train/Train\n","Tamaño de imagen: (180, 180), Tamaño de lote: 128\n","Modo de clase: 'categorical'\n","Parámetros de aumentación aplicados: {'rotation_range': 25, 'horizontal_flip': True, 'zoom_range': 0.3, 'fill_mode': 'reflect'}\n","Found 1322 images belonging to 3 classes.\n","Generador de entrenamiento creado. Encontradas 1322 imágenes pertenecientes a 3 clases.\n","\n","--- Información del Generador de Entrenamiento ---\n","Número TOTAL de imágenes en el dataset: 1322\n","Número de clases detectadas: 3\n","Nombres de las clases: ['Healthy', 'Powdery', 'Rust']\n","Imágenes por batch (tamaño del lote): 128\n","Número de batches por época (steps_per_epoch): 11\n","\n","¡Generador de entrenamiento listo para usar!\n"]}],"source":["if __name__ == \"__main__\":\n","    import os\n","\n","    # Definir los parámetros para el generador\n","    train_data_directory = '/content/drive/MyDrive/DL-Proyecto/Data/Train/Train'\n","    IMG_HEIGHT = 180\n","    IMG_WIDTH = 180\n","    BATCH_SIZE = 128\n","    CLASS_MODE = 'categorical' # También puedes usar 'binary' para 2 clases\n","\n","    # Opcional: Parámetros de aumentación personalizados (si no los pasas, usa los predeterminados)\n","    my_custom_augmentation_params = {\n","        'rotation_range': 25,\n","        'horizontal_flip': True,\n","        'zoom_range': 0.3,\n","        'fill_mode': 'reflect'\n","    }\n","\n","    try:\n","        # Llama a la función para crear el generador de entrenamiento\n","        train_generator_instance = create_augmented_train_generator(\n","            data_directory=train_data_directory,\n","            image_height=IMG_HEIGHT,\n","            image_width=IMG_WIDTH,\n","            batch_size=BATCH_SIZE,\n","            class_mode=CLASS_MODE,\n","            augmentation_params=my_custom_augmentation_params\n","        )\n","\n","        total_images = train_generator_instance.samples\n","        num_classes = train_generator_instance.num_classes\n","        class_names = list(train_generator_instance.class_indices.keys())\n","        images_per_batch = train_generator_instance.batch_size\n","        steps_per_epoch = train_generator_instance.samples // train_generator_instance.batch_size\n","        # Si el número de samples no es un múltiplo exacto del batch_size, habrá un batch incompleto\n","        if train_generator_instance.samples % train_generator_instance.batch_size != 0:\n","            steps_per_epoch += 1 # Suma 1 para el último batch incompleto\n","\n","        print(\"\\n--- Información del Generador de Entrenamiento ---\")\n","        print(f\"Número TOTAL de imágenes en el dataset: {total_images}\")\n","        print(f\"Número de clases detectadas: {num_classes}\")\n","        print(f\"Nombres de las clases: {class_names}\")\n","        print(f\"Imágenes por batch (tamaño del lote): {images_per_batch}\")\n","        print(f\"Número de batches por época (steps_per_epoch): {steps_per_epoch}\")\n","\n","        print(\"\\n¡Generador de entrenamiento listo para usar!\")\n","\n","    except FileNotFoundError as e:\n","        print(f\"Error al cargar el generador: {e}\")\n","    except Exception as e:\n","        print(f\"Ocurrió un error inesperado: {e}\")"]},{"cell_type":"markdown","metadata":{"id":"p456ZV_SG5UR"},"source":["## Generación de script `loading.py` para datos de entreamiento\n","\n","Se usa el comando mágico `%%writefile` para escribir el código Python de la celda en un archivo llamado `loading.py` dentro del directorio `./src/nombre_paquete/preprocessing/`. Esto forma parte de la estructuración del proyecto como un paquete de Python."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1753382370456,"user":{"displayName":"Daniel Tejada Hernandez","userId":"08292253613217380086"},"user_tz":300},"id":"pZ-Cw76ukPdF","outputId":"2bc9fb21-fc94-4a96-8365-d75290253508"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting ./src/nombre_paquete/preprocessing/loading.py\n"]}],"source":["%%writefile ./src/nombre_paquete/preprocessing/loading.py\n","from pathlib import Path\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from typing import Tuple, Dict, Any, Literal, Union\n","\n","def create_augmented_train_generator(\n","    data_directory: str,\n","    image_height: int,\n","    image_width: int,\n","    batch_size: int,\n","    class_mode: Literal['categorical', 'binary', 'sparse', 'input', 'multi_output', None] = 'categorical',\n","    augmentation_params: Dict[str, Any] | None = None\n",") -> tf.keras.preprocessing.image.DirectoryIterator:\n","    \"\"\"\n","    Crea un generador de datos de imágenes para el conjunto de entrenamiento con aumentación.\n","\n","    Utiliza `tf.keras.preprocessing.image.ImageDataGenerator` para cargar imágenes\n","    desde un directorio y aplicar transformaciones de aumentación de datos.\n","\n","    Args:\n","        data_directory (str): La ruta al directorio raíz que contiene las imágenes de entrenamiento,\n","                              organizadas en subdirectorios por clase.\n","        image_height (int): La altura deseada de las imágenes de salida en píxeles.\n","        image_width (int): El ancho deseado de las imágenes de salida en píxeles.\n","        batch_size (int): El número de imágenes por lote (batch) que generará el iterador.\n","        class_mode (Literal): El modo de clase para las etiquetas. Puede ser 'categorical',\n","                              'binary', 'sparse', 'input', 'multi_output', o None.\n","                              Por defecto es 'categorical'.\n","        augmentation_params (Dict[str, Any] | None, opcional): Un diccionario que contiene\n","                                    los parámetros para las transformaciones de aumentación de datos\n","                                    que se aplicarán (ej. 'rotation_range', 'zoom_range', etc.).\n","                                    Si es `None`, se utiliza un conjunto de parámetros predeterminado\n","                                    (similar al de tu ejemplo original). Por defecto es `None`.\n","\n","    Returns:\n","        tf.keras.preprocessing.image.DirectoryIterator: Un objeto iterador de Keras\n","                                                        que genera lotes de imágenes\n","                                                        y etiquetas aumentadas.\n","\n","    Raises:\n","        FileNotFoundError: Si el directorio de datos especificado no existe.\n","    \"\"\"\n","    # Verifica si el directorio existe\n","    if not Path(data_directory).is_dir():\n","        raise FileNotFoundError(f\"El directorio de datos de entrenamiento no existe: {data_directory}\")\n","\n","    # Parámetros de aumentación predeterminados si no se proporcionan\n","    if augmentation_params is None:\n","        augmentation_params = {\n","            'rotation_range': 20,\n","            'width_shift_range': 0.2,\n","            'height_shift_range': 0.2,\n","            'shear_range': 0.2,\n","            'zoom_range': 0.2,\n","            'horizontal_flip': True,\n","            'fill_mode': 'nearest'\n","        }\n","\n","    # Crear el ImageDataGenerator con reescalado y parámetros de aumentación\n","    data_generator = ImageDataGenerator(rescale=1./255, **augmentation_params)\n","\n","    print(f\"Creando generador de entrenamiento desde: {data_directory}\")\n","    print(f\"Tamaño de imagen: ({image_height}, {image_width}), Tamaño de lote: {batch_size}\")\n","    print(f\"Modo de clase: '{class_mode}'\")\n","    print(\"Parámetros de aumentación aplicados:\", augmentation_params)\n","\n","    # Crear el generador a partir del directorio\n","    generator = data_generator.flow_from_directory(\n","        directory=data_directory,\n","        target_size=(image_height, image_width),\n","        batch_size=batch_size,\n","        class_mode=class_mode\n","    )\n","\n","    print(f\"Generador de entrenamiento creado. Encontradas {generator.samples} imágenes pertenecientes a {generator.num_classes} clases.\")\n","\n","    return generator\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"O7xOfbZcJKAw"},"source":["## Guardar cambios en el repositorio de código"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":298,"status":"ok","timestamp":1753382370755,"user":{"displayName":"Daniel Tejada Hernandez","userId":"08292253613217380086"},"user_tz":300},"id":"9wIfykQP-Wcu","outputId":"68977367-357f-4c93-c1f8-435f6517e6d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["On branch main\n","Your branch is ahead of 'origin/main' by 2 commits.\n","  (use \"git push\" to publish your local commits)\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mmodified:   src/nombre_paquete/evaluation/app.py\u001b[m\n","\t\u001b[31mmodified:   src/nombre_paquete/preprocessing/loading.py\u001b[m\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\t\u001b[31msrc/nombre_paquete/evaluation/app2.py\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}],"source":["!git status"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":809,"status":"ok","timestamp":1753382371590,"user":{"displayName":"Daniel Tejada Hernandez","userId":"08292253613217380086"},"user_tz":300},"id":"58VW4KS6-dA1","outputId":"4cf5cf2e-3fd8-45cb-c3f0-7bf132ad2969"},"outputs":[{"name":"stdout","output_type":"stream","text":["[main 0939669] Modificación de funciones de carga y data augmentation para datos de entrenamiento\n"," 3 files changed, 64 insertions(+), 84 deletions(-)\n"," create mode 100644 src/nombre_paquete/evaluation/app2.py\n"]}],"source":["!git add .\n","!git commit -m \"Modificación de funciones de carga y data augmentation para datos de entrenamiento\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1089,"status":"ok","timestamp":1753382372691,"user":{"displayName":"Daniel Tejada Hernandez","userId":"08292253613217380086"},"user_tz":300},"id":"TPLbuwz7-zOF","outputId":"71bf2629-a971-4699-9607-38ac28506d9c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enumerating objects: 16, done.\n","Counting objects:   6% (1/16)\rCounting objects:  12% (2/16)\rCounting objects:  18% (3/16)\rCounting objects:  25% (4/16)\rCounting objects:  31% (5/16)\rCounting objects:  37% (6/16)\rCounting objects:  43% (7/16)\rCounting objects:  50% (8/16)\rCounting objects:  56% (9/16)\rCounting objects:  62% (10/16)\rCounting objects:  68% (11/16)\rCounting objects:  75% (12/16)\rCounting objects:  81% (13/16)\rCounting objects:  87% (14/16)\rCounting objects:  93% (15/16)\rCounting objects: 100% (16/16)\rCounting objects: 100% (16/16), done.\n","Delta compression using up to 2 threads\n","Compressing objects:  11% (1/9)\rCompressing objects:  22% (2/9)\rCompressing objects:  33% (3/9)\rCompressing objects:  44% (4/9)\rCompressing objects:  55% (5/9)\rCompressing objects:  66% (6/9)\rCompressing objects:  77% (7/9)\rCompressing objects:  88% (8/9)\rCompressing objects: 100% (9/9)\rCompressing objects: 100% (9/9), done.\n","Writing objects:  11% (1/9)\rWriting objects:  22% (2/9)\rWriting objects:  33% (3/9)\rWriting objects:  44% (4/9)\rWriting objects:  55% (5/9)\rWriting objects:  66% (6/9)\rWriting objects:  77% (7/9)\rWriting objects:  88% (8/9)\rWriting objects: 100% (9/9)\rWriting objects: 100% (9/9), 1.98 KiB | 135.00 KiB/s, done.\n","Total 9 (delta 6), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (6/6), completed with 6 local objects.\u001b[K\n","To https://github.com/Estefania5310/Proyecto_MDS6.git\n","   e068303..0939669  main -> main\n"]}],"source":["!git push https://{TOKEN_GITHUB}@github.com/Estefania5310/Proyecto_MDS6.git main"]},{"cell_type":"markdown","metadata":{"id":"Cr-I3HnDHE0K"},"source":["## Evaluación de la función de los datos de validación y prueba\n","\n","Se define la función `create_val_test_generators` que también utiliza `tf.keras.preprocessing.image.ImageDataGenerator` para crear generadores de datos, pero específicamente para los conjuntos de validación y prueba. A diferencia del generador de entrenamiento, este solo aplica reescalado (normalización) y no aumentación de datos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YpZHTUjJE7YR"},"outputs":[],"source":["from pathlib import Path\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from typing import Tuple, Dict, Any, Literal, Union\n","\n","\n","def create_val_test_generators(\n","    validation_data_directory: str,\n","    test_data_directory: str,\n","    image_height: int,\n","    image_width: int,\n","    batch_size: int,\n","    class_mode: Literal['categorical', 'binary', 'sparse', 'input', 'multi_output', None] = 'categorical',\n","    rescale_factor: float = 1./255\n",") -> Tuple[tf.keras.preprocessing.image.DirectoryIterator,\n","           tf.keras.preprocessing.image.DirectoryIterator]:\n","    \"\"\"\n","    Crea generadores de datos de imágenes para los conjuntos de validación y prueba.\n","\n","    Aplica únicamente el reescalado (normalización) a los píxeles de las imágenes,\n","    sin ninguna otra transformación de aumentación de datos.\n","\n","    Args:\n","        validation_data_directory (str): La ruta al directorio raíz que contiene las imágenes\n","                                         del conjunto de validación.\n","        test_data_directory (str): La ruta al directorio raíz que contiene las imágenes\n","                                   del conjunto de prueba.\n","        image_height (int): La altura deseada de las imágenes de salida en píxeles.\n","        image_width (int): El ancho deseado de las imágenes de salida en píxeles.\n","        batch_size (int): El número de imágenes por lote (batch) que generará el iterador.\n","        class_mode (Literal): El modo de clase para las etiquetas. Puede ser 'categorical',\n","                              'binary', 'sparse', 'input', 'multi_output', o None.\n","                              Por defecto es 'categorical'.\n","        rescale_factor (float, opcional): El factor para reescalar los valores de los píxeles.\n","                                          Por defecto es 1./255 para normalizar a [0, 1].\n","\n","    Returns:\n","        Tuple[tf.keras.preprocessing.image.DirectoryIterator,\n","              tf.keras.preprocessing.image.DirectoryIterator]:\n","            Una tupla que contiene (validation_generator, test_generator).\n","\n","    Raises:\n","        FileNotFoundError: Si alguno de los directorios de datos especificados no existe.\n","    \"\"\"\n","    # Verificar si los directorios existen\n","    if not Path(validation_data_directory).is_dir():\n","        raise FileNotFoundError(f\"El directorio de datos de validación no existe: {validation_data_directory}\")\n","    if not Path(test_data_directory).is_dir():\n","        raise FileNotFoundError(f\"El directorio de datos de prueba no existe: {test_data_directory}\")\n","\n","    # Crear el ImageDataGenerator para validación y prueba (solo reescalado)\n","    val_test_datagen = ImageDataGenerator(rescale=rescale_factor)\n","\n","    print(\"Creando generadores de datos para validación y prueba...\")\n","    print(f\"Tamaño de imagen: ({image_height}, {image_width}), Tamaño de lote: {batch_size}\")\n","    print(f\"Modo de clase: '{class_mode}'\")\n","    print(f\"Reescalado aplicado: {rescale_factor}\")\n","\n","    # Generador para el conjunto de validación\n","    val_generator = val_test_datagen.flow_from_directory(\n","        directory=validation_data_directory,\n","        target_size=(image_height, image_width),\n","        batch_size=batch_size,\n","        class_mode=class_mode,\n","        shuffle=True # Generalmente se baraja la validación para diversidad de batches, pero no es crítico\n","    )\n","\n","    # Generador para el conjunto de prueba\n","    test_generator = val_test_datagen.flow_from_directory(\n","        directory=test_data_directory,\n","        target_size=(image_height, image_width),\n","        batch_size=batch_size,\n","        class_mode=class_mode,\n","        shuffle=False  # ¡IMPORTANTE! No barajar el conjunto de prueba para resultados reproducibles\n","    )\n","\n","    print(f\"\\nGenerador de validación creado. Encontradas {val_generator.samples} imágenes pertenecientes a {val_generator.num_classes} clases.\")\n","    print(f\"Generador de prueba creado. Encontradas {test_generator.samples} imágenes pertenecientes a {test_generator.num_classes} clases.\")\n","\n","    return val_generator, test_generator"]},{"cell_type":"markdown","metadata":{"id":"rJ6K8MF3HYmB"},"source":["## Ejemplo de uso de la función de validación y prueba"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":627},"executionInfo":{"elapsed":4854,"status":"error","timestamp":1753382377581,"user":{"displayName":"Daniel Tejada Hernandez","userId":"08292253613217380086"},"user_tz":300},"id":"ZExWujAOFJ9a","outputId":"4efd1213-98f4-4f47-80d0-c01554a52a98"},"outputs":[{"name":"stdout","output_type":"stream","text":["Creando generadores de datos para validación y prueba...\n","Tamaño de imagen: (180, 180), Tamaño de lote: 128\n","Modo de clase: 'categorical'\n","Reescalado aplicado: 0.00392156862745098\n","Found 60 images belonging to 3 classes.\n","Found 150 images belonging to 3 classes.\n","\n","Generador de validación creado. Encontradas 60 imágenes pertenecientes a 3 clases.\n","Generador de prueba creado. Encontradas 150 imágenes pertenecientes a 3 clases.\n","\n","¡Generadores de validación y prueba creados exitosamente!\n","\n","Verificando un batch del generador de validación:\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-37-1514544544.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Opcional: Verificar un lote de imágenes y etiquetas del generador de validación\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nVerificando un batch del generador de validación:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_generator_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape de las imágenes del batch de validación: {val_images.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Valores de píxeles (min/max): {val_images.min():.4f}, {val_images.max():.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mfilepaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             img = image_utils.load_img(\n\u001b[0m\u001b[1;32m    314\u001b[0m                 \u001b[0mfilepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         raise TypeError(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["if __name__ == \"__main__\":\n","    import os\n","\n","    # Definir las rutas (reemplaza con tus rutas reales de Google Drive)\n","    validation_data_directory =  '/content/drive/MyDrive/DL-Proyecto/Data/Validation/Validation'\n","    test_data_directory = '/content/drive/MyDrive/DL-Proyecto/Data/Test/Test'\n","\n","    # Parámetros comunes para el tamaño de imagen y batch\n","    IMG_HEIGHT = 180\n","    IMG_WIDTH = 180\n","    BATCH_SIZE = 128\n","    CLASS_MODE = 'categorical' # O 'binary' si solo tienes 2 clases\n","\n","    try:\n","        # Llama a la función para crear los generadores de validación y prueba\n","        val_generator_instance, test_generator_instance = create_val_test_generators(\n","            validation_data_directory=validation_data_directory,\n","            test_data_directory=test_data_directory,\n","            image_height=IMG_HEIGHT,\n","            image_width=IMG_WIDTH,\n","            batch_size=BATCH_SIZE,\n","            class_mode=CLASS_MODE\n","        )\n","\n","        print(\"\\n¡Generadores de validación y prueba creados exitosamente!\")\n","\n","        # Opcional: Verificar un lote de imágenes y etiquetas del generador de validación\n","        print(\"\\nVerificando un batch del generador de validación:\")\n","        val_images, val_labels = next(val_generator_instance)\n","        print(f\"Shape de las imágenes del batch de validación: {val_images.shape}\")\n","        print(f\"Valores de píxeles (min/max): {val_images.min():.4f}, {val_images.max():.4f}\")\n","\n","        # Opcional: Verificar un lote de imágenes y etiquetas del generador de prueba\n","        print(\"\\nVerificando un batch del generador de prueba:\")\n","        test_images, test_labels = next(test_generator_instance)\n","        print(f\"Shape de las imágenes del batch de prueba: {test_images.shape}\")\n","        print(f\"Valores de píxeles (min/max): {test_images.min():.4f}, {test_images.max():.4f}\")\n","\n","    except FileNotFoundError as e:\n","        print(f\"Error: {e}. Por favor, verifica las rutas de tus directorios de datos.\")\n","    except Exception as e:\n","        print(f\"Ocurrió un error inesperado: {e}\")\n"]},{"cell_type":"markdown","metadata":{"id":"gTB4Q_6JJY-X"},"source":["## Agregar función de validación y prueba al script `loading.py`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SddTK7nqJV5_"},"outputs":[],"source":["%%writefile ./src/nombre_paquete/preprocessing/loading.py\n","from pathlib import Path\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from typing import Tuple, Dict, Any, Literal, Union\n","\n","def create_augmented_train_generator(\n","    data_directory: str,\n","    image_height: int,\n","    image_width: int,\n","    batch_size: int,\n","    class_mode: Literal['categorical', 'binary', 'sparse', 'input', 'multi_output', None] = 'categorical',\n","    augmentation_params: Dict[str, Any] | None = None\n",") -> tf.keras.preprocessing.image.DirectoryIterator:\n","    \"\"\"\n","    Crea un generador de datos de imágenes para el conjunto de entrenamiento con aumentación.\n","\n","    Utiliza `tf.keras.preprocessing.image.ImageDataGenerator` para cargar imágenes\n","    desde un directorio y aplicar transformaciones de aumentación de datos.\n","\n","    Args:\n","        data_directory (str): La ruta al directorio raíz que contiene las imágenes de entrenamiento,\n","                              organizadas en subdirectorios por clase.\n","        image_height (int): La altura deseada de las imágenes de salida en píxeles.\n","        image_width (int): El ancho deseado de las imágenes de salida en píxeles.\n","        batch_size (int): El número de imágenes por lote (batch) que generará el iterador.\n","        class_mode (Literal): El modo de clase para las etiquetas. Puede ser 'categorical',\n","                              'binary', 'sparse', 'input', 'multi_output', o None.\n","                              Por defecto es 'categorical'.\n","        augmentation_params (Dict[str, Any] | None, opcional): Un diccionario que contiene\n","                                    los parámetros para las transformaciones de aumentación de datos\n","                                    que se aplicarán (ej. 'rotation_range', 'zoom_range', etc.).\n","                                    Si es `None`, se utiliza un conjunto de parámetros predeterminado\n","                                    (similar al de tu ejemplo original). Por defecto es `None`.\n","\n","    Returns:\n","        tf.keras.preprocessing.image.DirectoryIterator: Un objeto iterador de Keras\n","                                                        que genera lotes de imágenes\n","                                                        y etiquetas aumentadas.\n","\n","    Raises:\n","        FileNotFoundError: Si el directorio de datos especificado no existe.\n","    \"\"\"\n","    # Verifica si el directorio existe\n","    if not Path(data_directory).is_dir():\n","        raise FileNotFoundError(f\"El directorio de datos de entrenamiento no existe: {data_directory}\")\n","\n","    # Parámetros de aumentación predeterminados si no se proporcionan\n","    if augmentation_params is None:\n","        augmentation_params = {\n","            'rotation_range': 20,\n","            'width_shift_range': 0.2,\n","            'height_shift_range': 0.2,\n","            'shear_range': 0.2,\n","            'zoom_range': 0.2,\n","            'horizontal_flip': True,\n","            'fill_mode': 'nearest'\n","        }\n","\n","    # Crear el ImageDataGenerator con reescalado y parámetros de aumentación\n","    data_generator = ImageDataGenerator(rescale=1./255, **augmentation_params)\n","\n","    print(f\"Creando generador de entrenamiento desde: {data_directory}\")\n","    print(f\"Tamaño de imagen: ({image_height}, {image_width}), Tamaño de lote: {batch_size}\")\n","    print(f\"Modo de clase: '{class_mode}'\")\n","    print(\"Parámetros de aumentación aplicados:\", augmentation_params)\n","\n","    # Crear el generador a partir del directorio\n","    generator = data_generator.flow_from_directory(\n","        directory=data_directory,\n","        target_size=(image_height, image_width),\n","        batch_size=batch_size,\n","        class_mode=class_mode\n","    )\n","\n","    print(f\"Generador de entrenamiento creado. Encontradas {generator.samples} imágenes pertenecientes a {generator.num_classes} clases.\")\n","\n","    return generator\n","\n","def create_val_test_generators(\n","    validation_data_directory: str,\n","    test_data_directory: str,\n","    image_height: int,\n","    image_width: int,\n","    batch_size: int,\n","    class_mode: Literal['categorical', 'binary', 'sparse', 'input', 'multi_output', None] = 'categorical',\n","    rescale_factor: float = 1./255\n",") -> Tuple[tf.keras.preprocessing.image.DirectoryIterator,\n","           tf.keras.preprocessing.image.DirectoryIterator]:\n","    \"\"\"\n","    Crea generadores de datos de imágenes para los conjuntos de validación y prueba.\n","\n","    Aplica únicamente el reescalado (normalización) a los píxeles de las imágenes,\n","    sin ninguna otra transformación de aumentación de datos.\n","\n","    Args:\n","        validation_data_directory (str): La ruta al directorio raíz que contiene las imágenes\n","                                         del conjunto de validación.\n","        test_data_directory (str): La ruta al directorio raíz que contiene las imágenes\n","                                   del conjunto de prueba.\n","        image_height (int): La altura deseada de las imágenes de salida en píxeles.\n","        image_width (int): El ancho deseado de las imágenes de salida en píxeles.\n","        batch_size (int): El número de imágenes por lote (batch) que generará el iterador.\n","        class_mode (Literal): El modo de clase para las etiquetas. Puede ser 'categorical',\n","                              'binary', 'sparse', 'input', 'multi_output', o None.\n","                              Por defecto es 'categorical'.\n","        rescale_factor (float, opcional): El factor para reescalar los valores de los píxeles.\n","                                          Por defecto es 1./255 para normalizar a [0, 1].\n","\n","    Returns:\n","        Tuple[tf.keras.preprocessing.image.DirectoryIterator,\n","              tf.keras.preprocessing.image.DirectoryIterator]:\n","            Una tupla que contiene (validation_generator, test_generator).\n","\n","    Raises:\n","        FileNotFoundError: Si alguno de los directorios de datos especificados no existe.\n","    \"\"\"\n","    # Verificar si los directorios existen\n","    if not Path(validation_data_directory).is_dir():\n","        raise FileNotFoundError(f\"El directorio de datos de validación no existe: {validation_data_directory}\")\n","    if not Path(test_data_directory).is_dir():\n","        raise FileNotFoundError(f\"El directorio de datos de prueba no existe: {test_data_directory}\")\n","\n","    # Crear el ImageDataGenerator para validación y prueba (solo reescalado)\n","    val_test_datagen = ImageDataGenerator(rescale=rescale_factor)\n","\n","    print(\"Creando generadores de datos para validación y prueba...\")\n","    print(f\"Tamaño de imagen: ({image_height}, {image_width}), Tamaño de lote: {batch_size}\")\n","    print(f\"Modo de clase: '{class_mode}'\")\n","    print(f\"Reescalado aplicado: {rescale_factor}\")\n","\n","    # Generador para el conjunto de validación\n","    val_generator = val_test_datagen.flow_from_directory(\n","        directory=validation_data_directory,\n","        target_size=(image_height, image_width),\n","        batch_size=batch_size,\n","        class_mode=class_mode,\n","        shuffle=True # Generalmente se baraja la validación para diversidad de batches, pero no es crítico\n","    )\n","\n","    # Generador para el conjunto de prueba\n","    test_generator = val_test_datagen.flow_from_directory(\n","        directory=test_data_directory,\n","        target_size=(image_height, image_width),\n","        batch_size=batch_size,\n","        class_mode=class_mode,\n","        shuffle=False  # ¡IMPORTANTE! No barajar el conjunto de prueba para resultados reproducibles\n","    )\n","\n","    print(f\"\\nGenerador de validación creado. Encontradas {val_generator.samples} imágenes pertenecientes a {val_generator.num_classes} clases.\")\n","    print(f\"Generador de prueba creado. Encontradas {test_generator.samples} imágenes pertenecientes a {test_generator.num_classes} clases.\")\n","\n","    return val_generator, test_generator"]},{"cell_type":"markdown","metadata":{"id":"kI2PYQNOJ5e3"},"source":["## Actualizar cambios en github"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3jRGNl0SJ9V_"},"outputs":[],"source":["!git status"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JeDyUQEtJ9NY"},"outputs":[],"source":["!git add .\n","!git commit -m \"Adición de funciones de carga y escalado para datos de validación y prueba\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vDAmHXoRKScf"},"outputs":[],"source":["!git push https://{TOKEN_GITHUB}@github.com/Estefania5310/Proyecto_MDS6.git main"]},{"cell_type":"markdown","metadata":{"id":"cpX7xdKFHgdQ"},"source":["# Uso de las funciones desde el paquete\n","\n","Se importa las funciones `create_augmented_train_generator` y `create_val_test_generators` directamente del módulo `src.nombre_paquete.preprocessing.loading`. Esto indica que el directorio `src` se ha agregado exitosamente a la ruta de Python y que la estructura del paquete es reconocida."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cdJzlRu9mt0D"},"outputs":[],"source":["from src.nombre_paquete.preprocessing.loading import create_augmented_train_generator, create_val_test_generators"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dZj7KsZO2bxK"},"outputs":[],"source":["train_generator = create_augmented_train_generator(data_directory='/content/drive/MyDrive/DL-Proyecto/Data/Train/Train',\n","                                                   image_height=180,\n","                                                   image_width=180,\n","                                                   batch_size=128,\n","                                                   class_mode='categorical')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hM8MH8fdKVnH"},"outputs":[],"source":["val_generator, test_generator = create_val_test_generators(validation_data_directory= '/content/drive/MyDrive/DL-Proyecto/Data/Validation/Validation',\n","                                           test_data_directory ='/content/drive/MyDrive/DL-Proyecto/Data//Test/Test',\n","                                           image_height=180,\n","                                           image_width=180,\n","                                           batch_size=128,\n","                                           class_mode='categorical')"]},{"cell_type":"markdown","metadata":{"id":"WiV3w9phpIFL"},"source":["# Funciones relacionadas al modelo y entrenamiento"]},{"cell_type":"markdown","metadata":{"id":"G8nZwFwcpSj_"},"source":["## Función para la definición del modelo\n","\n","Se define la función `build_cnn_model`, que crea un modelo de red neuronal convolucional (CNN) utilizando la API Sequential de Keras.\n","\n","La función es altamente configurable, permitiendo definir la forma de entrada, el número de clases, la cantidad de capas convolucionales, el número inicial de filtros, el tamaño del kernel, la función de activación, la inclusión opcional de una capa densa intermedia, el optimizador, la tasa de aprendizaje, la función de pérdida y las métricas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gxKHHhR8u12g"},"outputs":[],"source":["%%writefile ./src/nombre_paquete/models/model.py\n","from tensorflow import keras\n","def build_cnn_model(\n","    input_shape,\n","    num_classes,\n","    num_conv_layers=3,         # Número de bloques Conv2D-MaxPooling\n","    initial_filters=32,        # Número de filtros en la primera capa convolucional\n","    kernel_size=(3, 3),        # Tamaño del kernel para todas las capas convolucionales\n","    conv_activation='relu',    # Función de activación para capas convolucionales\n","    dense_units=None,          # Número de unidades en la capa densa antes de la salida\n","    optimizer_name='adam',     # Nombre del optimizador\n","    learning_rate=1e-3,        # Tasa de aprendizaje\n","    loss_function='categorical_crossentropy', # Función de pérdida\n","    metrics=['accuracy']       # Métricas a monitorear\n","):\n","    \"\"\"\n","    Crea un modelo de red neuronal convolucional (CNN) configurable.\n","\n","    Args:\n","        input_shape (tuple): La forma de las imágenes de entrada (alto, ancho, canales).\n","        num_classes (int): El número de clases para la clasificación.\n","        num_conv_layers (int): Número de bloques Conv2D + MaxPooling.\n","        initial_filters (int): Número de filtros en la primera capa convolucional.\n","                                Este número se duplica en cada capa subsiguiente.\n","        kernel_size (tuple): Tamaño del kernel para las capas Conv2D.\n","        conv_activation (str): Función de activación para las capas convolucionales.\n","        dense_units (int, optional): Número de unidades en la capa densa antes de la salida.\n","                                     Si es None, no se añade una capa densa intermedia.\n","        optimizer_name (str): Nombre del optimizador ('adam', 'sgd', 'rmsprop', etc.).\n","        learning_rate (float): Tasa de aprendizaje para el optimizador.\n","        loss_function (str): Función de pérdida a usar.\n","        metrics (list): Lista de métricas para la compilación del modelo.\n","\n","    Returns:\n","        tf.keras.Model: El modelo CNN compilado.\n","    \"\"\"\n","    model = keras.models.Sequential()\n","\n","    # Añadir capas convolucionales y de pooling\n","    filters = initial_filters\n","    for i in range(num_conv_layers):\n","        if i == 0:\n","            # Primera capa: especificar input_shape\n","            model.add(keras.layers.Conv2D(filters, kernel_size, activation=conv_activation, input_shape=input_shape))\n","        else:\n","            # Capas subsiguientes: no necesitan input_shape\n","            model.add(keras.layers.Conv2D(filters, kernel_size, activation=conv_activation))\n","        model.add(keras.layers.MaxPooling2D((2, 2)))\n","        filters *= 2 # Duplicar los filtros para la siguiente capa\n","\n","    # Aplanar la salida para conectarla a las capas densas\n","    model.add(keras.layers.Flatten())\n","\n","    # Opcional: Capa densa intermedia\n","    if dense_units is not None:\n","        model.add(keras.layers.Dense(units=dense_units, activation='relu'))\n","\n","    # Capa de salida\n","    model.add(keras.layers.Dense(units=num_classes, activation='softmax'))\n","\n","    # Configurar el optimizador\n","    if optimizer_name == 'adam':\n","        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n","    elif optimizer_name == 'sgd':\n","        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n","    elif optimizer_name == 'rmsprop':\n","        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n","    else:\n","        raise ValueError(f\"Optimizer '{optimizer_name}' not supported.\")\n","\n","    # Compilar el modelo\n","    model.compile(optimizer=optimizer,\n","                  loss=loss_function,\n","                  metrics=metrics)\n","\n","    return model\n"]},{"cell_type":"markdown","metadata":{"id":"QlbixrvhvgwR"},"source":["# Funcion para callbacks\n","\n","Sefine la función `get_callbacks`, que crea y devuelve una lista de objetos `tf.keras`.callbacks comúnmente utilizados durante el entrenamiento de modelos en Keras. Específicamente, configura un callback para la detención temprana (EarlyStopping) y otro para guardar el mejor modelo (ModelCheckpoint).\n","\n","\n","Se incluye `EarlyStopping` para detener automáticamente el entrenamiento si la métrica monitoreada (por defecto, la pérdida en el conjunto de validación, val_loss) no mejora durante un número especificado de épocas (`patience`). También se usó `restore_best_weights=True` para que después de que el entrenamiento se detenga, el modelo cargue los pesos de la época que tuvo el mejor rendimiento según la métrica monitoreada.\n","\n","\n","También se incluye `ModelCheckpoint` para guardar el modelo automáticamente durante el entrenamiento.\n","`save_best_only=True` indica que solo se guardará la versión del modelo que haya logrado el mejor valor para la métrica monitor hasta el momento. Esto evita guardar modelos intermedios que no son los de mejor rendimiento.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aJxttx7Sve2g"},"outputs":[],"source":["%%writefile ./src/nombre_paquete/models/callbacks.py\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","def get_callbacks(model_save_path, patience=10, monitor='val_loss'):\n","    \"\"\"\n","    Genera una lista de callbacks para el entrenamiento del modelo.\n","\n","    Args:\n","        model_save_path (str): Ruta donde se guardará el mejor modelo.\n","        patience (int): Número de épocas sin mejora para EarlyStopping.\n","        monitor (str): Métrica a monitorear para EarlyStopping y ModelCheckpoint.\n","\n","    Returns:\n","        list: Una lista de objetos tf.keras.callbacks.\n","    \"\"\"\n","    early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n","        monitor=monitor,\n","        patience=patience,\n","        restore_best_weights=True\n","    )\n","\n","    checkpoint_cb = keras.callbacks.ModelCheckpoint(\n","        model_save_path,\n","        save_best_only=True,\n","        monitor=monitor # Aseguramos que el checkpoint también use el mismo monitor\n","    )\n","    return [checkpoint_cb, early_stopping_cb]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gEkGOJeowRAH"},"outputs":[],"source":["!git status\n","!git add .\n","!git commit -m \"Redefinición del modelo base y de los callbacks\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JSkK71cRts80"},"outputs":[],"source":["from src.nombre_paquete.models.model import build_cnn_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kzkbXj_euNAu"},"outputs":[],"source":["model = build_cnn_model(\n","    input_shape=(180, 180, 3),\n","    num_classes=3,\n","    num_conv_layers=3,\n","    initial_filters=32,\n","    kernel_size=(3, 3),\n","    conv_activation='relu',\n","    dense_units=None, # Sin capa densa intermedia\n","    optimizer_name='adam',\n","    learning_rate=3e-3,\n","    loss_function='categorical_crossentropy',\n","    metrics=['accuracy']\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xNm545aTvLvn"},"outputs":[],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"p03ygN9ax3N0"},"source":["## Función de entrenamiento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CAaxrOfr58sh"},"outputs":[],"source":["%%writefile ./src/nombre_paquete/training/train.py\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","def train_model(model, train_generator, val_generator, epochs, callbacks_list):\n","    \"\"\"\n","    Entrena un modelo de Keras utilizando generadores de datos.\n","\n","    Args:\n","        model (keras.Model): El modelo compilado a entrenar.\n","        train_generator (tf.keras.utils.Sequence): Generador de datos para entrenamiento.\n","        val_generator (tf.keras.utils.Sequence): Generador de datos para validación.\n","        epochs (int): Número de épocas para entrenar.\n","        callbacks_list (list): Lista de callbacks a usar durante el entrenamiento.\n","\n","    Returns:\n","        tf.keras.callbacks.History: Objeto History que contiene los registros de entrenamiento.\n","    \"\"\"\n","    print(\"\\n--- Iniciando el entrenamiento del modelo ---\")\n","    history = model.fit(\n","        train_generator,\n","        steps_per_epoch= train_generator.samples // train_generator.batch_size,\n","        epochs=epochs,\n","        validation_data= val_generator,\n","        validation_steps= val_generator.samples // val_generator.batch_size,\n","        callbacks=callbacks_list\n","    )\n","    print(\"--- Entrenamiento finalizado ---\")\n","    return history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i45aex1e7TvI"},"outputs":[],"source":["%%writefile ./src/nombre_paquete/evaluation/evaluate.py\n","import tensorflow as tf\n","\n","def evaluate_model(model, test_generator):\n","    \"\"\"\n","    Evalúa un modelo de Keras en un conjunto de prueba.\n","\n","    Args:\n","        model (keras.Model): El modelo a evaluar.\n","        test_generator (tf.keras.utils.Sequence): Generador de datos para el conjunto de prueba.\n","\n","    Returns:\n","        tuple: Una tupla que contiene la pérdida y la precisión del modelo en el conjunto de prueba.\n","    \"\"\"\n","    print(\"\\n--- Evaluando el modelo en el conjunto de prueba ---\")\n","    loss, accuracy = model.evaluate(test_generator)\n","    print(f\"Pérdida en el conjunto de prueba: {loss:.4f}\")\n","    print(f\"Precisión en el conjunto de prueba: {accuracy:.4f}\")\n","    return loss, accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S0IRaiTABJIp"},"outputs":[],"source":["!git status\n","!git add .\n","!git commit -m \"Se agregaron funciones para el entramiento y la evaluación del modelo\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3sH6kRzIBY2l"},"outputs":[],"source":["!git push https://{TOKEN_GITHUB}@github.com/Estefania5310/Proyecto_MDS6.git main"]},{"cell_type":"markdown","metadata":{"id":"QblyLnw4Tahq"},"source":["# Entrenamiento de CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eKzW7U882TMV"},"outputs":[],"source":["from src.nombre_paquete.models.callbacks import get_callbacks\n","from src.nombre_paquete.training.train import train_model\n","from src.nombre_paquete.evaluation.evaluate import evaluate_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6-hoKS1J2_Et"},"outputs":[],"source":["best_models_dir = '/content/drive/MyDrive/Proyecto_MDS6/src/nombre_paquete/models/best_models'\n","if not os.path.exists(best_models_dir):\n","    os.makedirs(best_models_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4naZ5w1f-N91"},"outputs":[],"source":["model_save_path = os.path.join(best_models_dir, '2_model.keras')\n","callbacks_list = get_callbacks(model_save_path=model_save_path, patience=10, monitor='val_loss')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1FPh9tQ19oWX"},"outputs":[],"source":["history = train_model(model, train_generator, val_generator, epochs=100, callbacks_list=callbacks_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4FnMqLB89xbi"},"outputs":[],"source":["loss, accuracy = evaluate_model(model, test_generator)"]},{"cell_type":"markdown","metadata":{"id":"0FOvVJjeVmXp"},"source":["# Carga de modelo entrenado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VVpDmAAgDYSe"},"outputs":[],"source":["model_path = '/content/drive/MyDrive/Proyecto_MDS6/src/nombre_paquete/models/best_models/2_model.keras'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2m_Shp1YDx9I"},"outputs":[],"source":["try:\n","    model = tf.keras.models.load_model(model_path)\n","    print(f\"Modelo cargado exitosamente desde: {model_path}\")\n","    model.summary()\n","\n","except Exception as e:\n","    print(f\"Error al cargar el modelo: {e}\")\n","    print(\"Asegúrate de que la ruta al archivo 'model.keras' sea correcta.\")"]},{"cell_type":"markdown","metadata":{"id":"umfUR-T-j98k"},"source":["# Predicciones sobre el modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HyAzSA-gV91Z"},"outputs":[],"source":["import joblib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xj-_-R3nV9sh"},"outputs":[],"source":["joblib.dump(model, \"src/nombre_paquete/models/best_models/model.joblib\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IKI6KP5GhVb-"},"outputs":[],"source":["model = joblib.load(\"src/nombre_paquete/models/best_models/model.joblib\")"]},{"cell_type":"markdown","metadata":{"id":"igMfXJbpg0V0"},"source":["## Ejemplo de preprocesamiento para la imagen sobre la que se quiere predecir"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h2uwVemzcg31"},"outputs":[],"source":["from tensorflow.keras.preprocessing import image\n","import numpy as np\n","\n","TARGET_HEIGHT = 180 # Altura esperada por el modelo\n","TARGET_WIDTH = 180  # Ancho esperado por el modelo\n","\n","# Ruta a la imagen que quieres predecir\n","img_path = '/content/drive/MyDrive/DL-Proyecto/Data/Test/Test/Healthy/8ddaa5a5caa5caa8.jpg'\n","\n","try:\n","  original_img = image.load_img(img_path)\n","  original_width, original_height = original_img.size\n","  img = image.load_img(img_path, target_size=(TARGET_WIDTH, TARGET_HEIGHT))\n","\n","  print(f\"Imagen cargada desde '{img_path}'.\")\n","  print(f\"Caracteristicas originales de la imagen: {image.load_img(img_path)}\")\n","  print(f\"Dimensiones originales de la imagen: ({original_width}, {original_height})\")\n","  # img.size devuelve (ancho, alto)\n","  print(f\"Dimensiones después de cargar y escalar (target_size): {img.size}\")\n","\n","  # El resto del preprocesamiento es el mismo que antes:\n","  # 1. Convertir la imagen a un array de NumPy\n","  img_array = image.img_to_array(img)\n","\n","  # 2. Añadir la dimensión de batch (importante para modelos que esperan lotes de imágenes)\n","  img_array = np.expand_dims(img_array, axis=0) # Ahora la forma es (1, alto, ancho, canales)\n","\n","  # 3. Aplicar el mismo escalado de píxeles usado durante el entrenamiento.\n","  # Se usó rescale=1./255 en ImageDataGenerator para normaliza los valores de píxeles a [0, 1].\n","  img_array = img_array / 255.0 #\n","  print(\"Preprocesamiento: valores de píxeles normalizados a [0, 1].\")\n","  print(\"\\nImagen lista para ser predicción.\")\n","  print(f\"Forma final del array de imagen: {img_array.shape}\")\n","\n","except FileNotFoundError:\n","    print(f\"Error: La imagen no se encontró en la ruta '{img_path}'. Por favor, verifica la ruta.\")\n","except Exception as e:\n","    print(f\"Ocurrió un error al procesar la imagen: {e}\")"]},{"cell_type":"markdown","metadata":{"id":"9-rYOeB9hNe7"},"source":["## Función de preprocesamiento de imagen (individual) para predicción"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O5S2y-6VfgjD"},"outputs":[],"source":["%%writefile ./src/nombre_paquete/preprocessing/preprocessing_prediction.py\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","\n","def preprocess_image_for_prediction(img_path, target_height=180, target_width=180):\n","    \"\"\"\n","    Carga, redimensiona y preprocesa una imagen para ser usada en un modelo de Keras.\n","\n","    Args:\n","        img_path (str): La ruta completa a la imagen.\n","        target_height (int): La altura a la que se debe redimensionar la imagen.\n","        target_width (int): El ancho a la que se debe redimensionar la imagen.\n","\n","    Returns:\n","        tuple: Una tupla que contiene:\n","            - img_array (np.ndarray): La imagen preprocesada lista para el modelo.\n","                                      None si ocurre un error.\n","            - original_dimensions (tuple): Las dimensiones originales (ancho, alto) de la imagen.\n","                                           None si ocurre un error.\n","    \"\"\"\n","    try:\n","        original_img = image.load_img(img_path)\n","        original_width, original_height = original_img.size\n","        original_dimensions = (original_width, original_height)\n","        img_for_prediction = image.load_img(img_path, target_size=(target_width, target_height))\n","        print(\"\\n--- Preprocesamiento de imagen ---\")\n","        print(f\"Imagen cargada desde: '{img_path}'.\")\n","        print(f\"Dimensiones originales de la imagen: {original_dimensions}\")\n","        print(f\"Dimensiones después de escalar (para el modelo): {img_for_prediction.size}\")\n","\n","\n","        img_array = image.img_to_array(img_for_prediction)\n","        img_array = np.expand_dims(img_array, axis=0)\n","        img_array = img_array / 255.0\n","        print(\"Preprocesamiento: valores de píxeles normalizados a [0, 1].\")\n","        print(f\"Forma final del array de imagen: {img_array.shape}\")\n","\n","        return img_array, original_dimensions\n","\n","    except FileNotFoundError:\n","        print(f\"Error: La imagen no se encontró en la ruta '{img_path}'. Por favor, verifica la ruta.\")\n","        return None, None\n","    except Exception as e:\n","        print(f\"Ocurrió un error al procesar la imagen: {e}\")\n","        return None, None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pPmSB9K7gHNz"},"outputs":[],"source":["from src.nombre_paquete.preprocessing.preprocessing_prediction import preprocess_image_for_prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D2wG8oTIjy8x"},"outputs":[],"source":["img_array, __ = preprocess_image_for_prediction(img_path = '/content/drive/MyDrive/DL-Proyecto/Data/Test/Test/Powdery/80bc7d353e163e85.jpg')\n","model.predict(img_array)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_v2o2Jrej69J"},"outputs":[],"source":["img_array, __ = preprocess_image_for_prediction(img_path = '/content/drive/MyDrive/DL-Proyecto/Data/Test/Test/Rust/82add70df6ab2854.jpg')\n","model.predict(img_array)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hD9HScRyk5pa"},"outputs":[],"source":["%%writefile ./src/nombre_paquete/evaluation/interpret_prediction.py\n","import numpy as np\n","\n","def interpret_prediction(predictions):\n","    \"\"\"\n","    Interpreta el resultado de model.predict() y muestra las probabilidades por clase.\n","\n","    Args:\n","        predictions (np.ndarray): El array de predicciones devuelto por model.predict().\n","                                  Debe ser un array 2D (ej: [[prob_clase1, prob_clase2, ...]])\n","        class_names (list): Una lista de strings con los nombres de las clases\n","                            en el mismo orden en que el modelo predice las probabilidades.\n","\n","    Returns:\n","        dict: Un diccionario con las probabilidades de cada clase,\n","              la clase predicha y su confianza.\n","              Retorna None si las dimensiones no coinciden.\n","    \"\"\"\n","    class_names = ['saludable', 'powdery', 'rush']\n","    if predictions.shape[0] == 0:\n","        print(\"Error: No se proporcionaron predicciones (array vacío).\")\n","        return None\n","\n","    # Si se predice una sola imagen, predictions[0] contiene las probabilidades\n","    probabilities = predictions[0]\n","\n","    if len(probabilities) != len(class_names):\n","        print(f\"Error: El número de probabilidades ({len(probabilities)}) no coincide \"\n","              f\"con el número de nombres de clases ({len(class_names)}). \"\n","              \"Verifica tu lista 'class_names'.\")\n","        return None\n","\n","    print(\"\\n--- Resultados Detallados de la Predicción ---\")\n","\n","    # Almacenar probabilidades en un diccionario para fácil acceso\n","    results = {}\n","    for i, prob in enumerate(probabilities):\n","        class_name = class_names[i]\n","        results[class_name] = float(prob) # Convertir a float estándar para el dict\n","        print(f\"  {class_name.capitalize()}: {prob:.8f} ({prob*100:.4f}%)\") # Más decimales para valores pequeños\n","\n","    # Encontrar la clase predicha (la de mayor probabilidad)\n","    predicted_class_index = np.argmax(probabilities)\n","    predicted_class_name = class_names[predicted_class_index]\n","    confidence = probabilities[predicted_class_index] * 100\n","    print(\"\\n--- Clasificación ---\")\n","    print(f\"La imagen se clasifica como: {predicted_class_name.capitalize()} \"\n","          f\"con una confianza del {confidence:.2f}%.\")\n","\n","    results['predicted_class'] = predicted_class_name\n","    results['confidence'] = confidence\n","\n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ARHDLsimZZI"},"outputs":[],"source":["from src.nombre_paquete.evaluation.interpret_prediction import interpret_prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ITHv5I7ylD_4"},"outputs":[],"source":["img_array, __ = preprocess_image_for_prediction(img_path = '/content/drive/MyDrive/DL-Proyecto/Data/Test/Test/Rust/82add70df6ab2854.jpg')\n","prediccion =  model.predict(img_array)\n","results = interpret_prediction(prediccion)\n","results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UxQsfMItmr83"},"outputs":[],"source":["!git status\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QKYzP0F4okH2"},"outputs":[],"source":["!git add .\n","!git commit -m \"Se agregan funciones para 1)preprocesamiento de imagenes individuales 2)Interpretación de resultados de predicción. Además se guarda modelo.\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OoT8hMM9pH-_"},"outputs":[],"source":["!git push https://{TOKEN_GITHUB}@github.com/Estefania5310/Proyecto_MDS6.git main"]},{"cell_type":"markdown","metadata":{"id":"EIDpuO9ApfBl"},"source":["# Despliegue"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IEsSDEX_poX5"},"outputs":[],"source":["import joblib\n","MODEL_PATH = \"./src/nombre_paquete/models/best_models/model.joblib\"\n","model = joblib.load(MODEL_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1753388634190,"user":{"displayName":"DANIEL TEJADA","userId":"09448008839633351094"},"user_tz":300},"id":"VEdsHs_-UVvN","outputId":"8cc7d33a-4a39-4873-e405-23a44b00ec0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Proyecto_MDS6\n"]}],"source":["%cd /content/drive/MyDrive/Proyecto_MDS6/"]},{"cell_type":"code","source":["%%writefile ./src/nombre_paquete/evaluation/app2.py\n","from fastapi import FastAPI, HTTPException, status, UploadFile, File # <-- ¡IMPORTANTE! Agrega UploadFile y File\n","from pydantic import BaseModel\n","from typing import Dict, List, Optional\n","import tensorflow as tf\n","import numpy as np\n","import joblib\n","import os # <-- ¡IMPORTANTE! Necesitas os para manejar archivos temporales\n","import shutil # <-- ¡OPCIONAL pero ÚTIL! Para guardar archivos de manera más robusta\n","\n","# Importa tus funciones de preprocesamiento e interpretación\n","# Asegúrate de que estas rutas sean correctas para tu estructura de proyecto\n","from src.nombre_paquete.preprocessing.preprocessing_prediction import preprocess_image_for_prediction\n","from src.nombre_paquete.evaluation.interpret_prediction import interpret_prediction\n","\n","# --- Configuración ---\n","MODEL_PATH = \"./src/nombre_paquete/models/best_models/model.joblib\"\n","\n","app = FastAPI(\n","    title=\"API DE CLASIFICACIÓN DE ENFERMEDADES DE PLANTAS\",\n","    description=\"API para clasificar imágenes saludables o afectadas por 2 enfermedades.\",\n","    version=\"1.0.0\"\n",")\n","\n","# ¡Carga del modelo al inicio de la aplicación!\n","# Mueve esta línea dentro de @app.on_event(\"startup\")\n","model = None # Inicializa como None\n","\n","class PredictionOutput(BaseModel):\n","    saludable: float\n","    powdery: float\n","    rush: float\n","    predicted_class: str\n","    confidence: float\n","\n","# --- Endpoint Raíz ---\n","@app.get(\"/\")\n","async def read_root():\n","    return {\"message\": \"¡API funcionando! Visita /docs para ver la documentación.\"}\n","\n","# --- Health Check Endpoint (Recomendado) ---\n","@app.get(\"/health\", status_code=status.HTTP_200_OK)\n","async def health_check():\n","    \"\"\"\n","    Verifica el estado de la API y si el modelo ha sido cargado exitosamente.\n","    \"\"\"\n","    if model is not None:\n","        return {\"status\": \"ok\", \"model_loaded\": True, \"message\": \"Modelo cargado y API lista.\"}\n","    else:\n","        raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE,\n","                            detail=\"Modelo no cargado. El servicio no está disponible.\")\n","\n","# --- Carga del modelo al inicio de la aplicación ---\n","@app.on_event(\"startup\")\n","async def load_model_on_startup():\n","    \"\"\"\n","    Carga el modelo de Joblib al iniciar la aplicación FastAPI.\n","    \"\"\"\n","    global model\n","    try:\n","        model = joblib.load(MODEL_PATH)\n","        print(f\"Modelo cargado exitosamente desde: {MODEL_PATH}\")\n","    except Exception as e:\n","        print(f\"Error al cargar el modelo desde '{MODEL_PATH}': {e}\")\n","        # Considera no levantar una excepción fatal aquí si quieres que la API inicie\n","        # pero sin el modelo cargado, y manejar el caso en el endpoint /predict\n","        # raise RuntimeError(f\"No se pudo cargar el modelo al iniciar la aplicación: {e}\")\n","    print(\"Startup event finished.\") # Debug print\n","\n","# --- Endpoint de Predicción ---\n","@app.post(\"/predict\", response_model=PredictionOutput)\n","# ¡IMPORTANTE! Cambia 'data: ImageInput' a 'file: UploadFile = File(...)'\n","# Esto le dice a FastAPI que esperas un archivo subido.\n","async def predict_plant_disease(file: UploadFile = File(...)):\n","    \"\"\"\n","    Recibe un archivo de imagen, lo guarda temporalmente, lo preprocesa\n","    y devuelve la predicción de la enfermedad de la planta.\n","    \"\"\"\n","    if model is None:\n","        raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE,\n","                            detail=\"El modelo no ha sido cargado todavía. Intente de nuevo en unos momentos.\")\n","\n","    # Definir una ruta temporal para guardar el archivo\n","    # Usamos os.path.join para construir rutas de forma segura en diferentes OS\n","    # Y un nombre único para evitar conflictos si muchas peticiones llegan a la vez\n","    temp_dir = \"/tmp\" # O \"./temp_uploads\" si quieres una carpeta local\n","    # Asegúrate de que el directorio exista\n","    os.makedirs(temp_dir, exist_ok=True)\n","    temp_file_path = os.path.join(temp_dir, f\"{os.urandom(16).hex()}_{file.filename}\")\n","\n","    try:\n","        # 1. Guardar el archivo subido en la ruta temporal\n","        # shutil.copyfileobj es eficiente para archivos grandes\n","        with open(temp_file_path, \"wb\") as buffer:\n","            shutil.copyfileobj(file.file, buffer)\n","        print(f\"Archivo temporal guardado en: {temp_file_path}\")\n","\n","        # 2. Preprocesar la imagen usando la ruta del archivo temporal\n","        # Tu función preprocess_image_for_prediction espera esta ruta\n","        img_array, _ = preprocess_image_for_prediction(img_path=temp_file_path)\n","        if img_array is None:\n","            # Si preprocess_image_for_prediction devuelve None, hubo un error (ej. archivo no es imagen)\n","            # La función ya imprime el error específico\n","            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Error al preprocesar la imagen. Asegúrate de que es una imagen válida.\")\n","\n","        # 3. Realizar la predicción\n","        # model.predict(img_array) devuelve un array de arrays (ej: [[prob_s, prob_p, prob_r]])\n","        # Usamos [0] para obtener el array plano de probabilidades para la única imagen procesada.\n","        probabilities = model.predict(img_array)[0]\n","\n","        # 4. Interpretar la predicción\n","        # Tu función interpret_prediction debe tomar este array plano de probabilidades\n","        # y la lista de nombres de clases, y devolver el diccionario esperado.\n","        # Asegúrate de que CLASS_NAMES está definido y en el orden correcto.\n","        # Aquí asumo que interpret_prediction ya tiene los nombres de clase, si no, pásalos como argumento.\n","        # Define CLASS_NAMES somewhere if needed, or update interpret_prediction\n","        # Example: CLASS_NAMES = ['Healthy', 'Powdery', 'Rust']\n","        results = interpret_prediction(probabilities) # Assuming interpret_prediction doesn't need class_names here\n","\n","        # 5. Retornar los resultados\n","        # FastAPI se encargará de mapear las claves del diccionario 'results'\n","        # a los campos de PredictionOutput y validar los tipos.\n","        return PredictionOutput(**results)\n","\n","    except Exception as e:\n","        # Captura cualquier error durante el proceso y devuélvelo como un error HTTP\n","        print(f\"Error en la predicción: {e}\")\n","        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n","                            detail=f\"Ocurrió un error en el servidor durante la predicción: {e}\")\n","    finally:\n","        # ¡IMPORTANTE! Asegúrate de borrar el archivo temporal, siempre.\n","        if os.path.exists(temp_file_path):\n","            os.remove(temp_file_path)\n","            print(f\"Archivo temporal eliminado: {temp_file_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tt-cqEP76uAv","executionInfo":{"status":"ok","timestamp":1753388851982,"user_tz":300,"elapsed":32,"user":{"displayName":"DANIEL TEJADA","userId":"09448008839633351094"}},"outputId":"3254a8b5-6664-4b0e-e8d6-5181317d60be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing ./src/nombre_paquete/evaluation/app2.py\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1753388861580,"user":{"displayName":"DANIEL TEJADA","userId":"09448008839633351094"},"user_tz":300},"id":"_1k4G8oqDY-8","outputId":"032b214a-7712-4d89-f8a7-b4169e448731"},"outputs":[{"output_type":"stream","name":"stdout","text":["¡Servidor de FastAPI iniciado! Ahora puedes probar los endpoints en una nueva celda.\n"]}],"source":["import nest_asyncio\n","import uvicorn\n","import threading\n","import sys\n","import os\n","\n","# Agrega la raíz de tu proyecto al path para que Python encuentre tu paquete\n","# Ajusta la ruta si es necesario\n","project_root = os.path.join(os.getcwd(), 'src')\n","if project_root not in sys.path:\n","    sys.path.append(project_root)\n","\n","# Necesario para ejecutar uvicorn dentro de un entorno como Jupyter\n","nest_asyncio.apply()\n","\n","# Importa tu aplicación FastAPI\n","from nombre_paquete.evaluation.app2 import app\n","\n","# Configuración del servidor Uvicorn\n","config = uvicorn.Config(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n","\n","# Crea una clase Server para ejecutar de forma no bloqueante\n","server = uvicorn.Server(config)\n","\n","# Inicia el servidor en un hilo separado\n","thread = threading.Thread(target=server.run)\n","thread.start()\n","\n","print(\"¡Servidor de FastAPI iniciado! Ahora puedes probar los endpoints en una nueva celda.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1753388872034,"user":{"displayName":"DANIEL TEJADA","userId":"09448008839633351094"},"user_tz":300},"id":"Ji4KttywRyUH","outputId":"ad26262d-76f3-403a-909f-9aeb3de420c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:     127.0.0.1:34590 - \"GET / HTTP/1.1\" 200 OK\n","¡La petición al endpoint raíz fue exitosa!\n","Código de estado: 200\n","Respuesta: {'message': '¡API funcionando! Visita /docs para ver la documentación.'}\n"]}],"source":["import requests\n","\n","url = \"http://0.0.0.0:8000/\"\n","\n","# Realiza una petición GET al endpoint\n","try:\n","    response = requests.get(url)\n","\n","    if response.status_code == 200:\n","        print(\"¡La petición al endpoint raíz fue exitosa!\")\n","        print(\"Código de estado:\", response.status_code)\n","        print(\"Respuesta:\", response.json())\n","    else:\n","        print(\"Hubo un error al conectar con el endpoint.\")\n","        print(\"Código de estado:\", response.status_code)\n","        print(\"Respuesta:\", response.text)\n","\n","except requests.exceptions.ConnectionError:\n","    print(\"Error: No se pudo conectar al servidor.\")\n","    print(\"Asegúrate de que el servidor de FastAPI esté iniciado y corriendo en la celda anterior.\")\n","except Exception as e:\n","    print(f\"Ocurrió un error inesperado: {e}\")"]},{"cell_type":"code","source":["import requests\n","import os\n","\n","DIRECCION_DE_MI_PROGRAMA = \"http://0.0.0.0:8000/predict\"\n","\n","NOMBRE_DE_LA_FOTO = \"/content/drive/MyDrive/DL-Proyecto/Data/Test/Test/Rust/82add70df6ab2854.jpg\"\n","\n","if __name__ == \"__main__\":\n","    print(f\"Intentando enviar '{NOMBRE_DE_LA_FOTO}' a mi programa...\")\n","\n","    if not os.path.exists(NOMBRE_DE_LA_FOTO):\n","        print(f\"¡Error! No encuentro la foto '{NOMBRE_DE_LA_FOTO}'.\")\n","        print(\"Asegúrate de que la foto esté en la misma carpeta donde guardaste este código.\")\n","    else:\n","        try:\n","            with open(NOMBRE_DE_LA_FOTO, \"rb\") as archivo_de_foto:\n","\n","                archivos_para_enviar = {'file': (NOMBRE_DE_LA_FOTO, archivo_de_foto)}\n","\n","                # Enviamos la foto a la dirección de tu programa.\n","                respuesta = requests.post(DIRECCION_DE_MI_PROGRAMA, files=archivos_para_enviar)\n","\n","                # Si la respuesta es buena (código 200), ¡éxito!\n","                respuesta.raise_for_status() # Esto nos avisa si hubo un error (400, 500, etc.)\n","\n","                resultados = respuesta.json()\n","\n","                print(\"\\n--- ¡Foto Enviada y Revisada! ---\")\n","                print(f\"El programa dice que la clase es: {resultados.get('predicted_class')}\")\n","                print(f\"Con una confianza del: {resultados.get('confidence'):.2f}%\")\n","                print(\"Probabilidades detalladas:\")\n","                print(f\"  Saludable: {resultados.get('saludable', 0.0):.2f}%\")\n","                print(f\"  Powdery: {resultados.get('powdery', 0.0):.2f}%\")\n","                print(f\"  Rush: {resultados.get('rush', 0.0):.2f}%\")\n","\n","        except requests.exceptions.ConnectionError:\n","            print(\"¡Error de conexión! No puedo conectar con tu programa.\")\n","            print(\"Asegúrate de que tu programa (FastAPI) esté encendido y funcionando.\")\n","        except Exception as e:\n","            print(f\"Algo salió mal al enviar la foto o al recibir la respuesta: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jNzBM8IuCrX7","executionInfo":{"status":"ok","timestamp":1753388883590,"user_tz":300,"elapsed":1923,"user":{"displayName":"DANIEL TEJADA","userId":"09448008839633351094"}},"outputId":"1a44f461-79da-4b51-b0c5-fb3d540ba594"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Intentando enviar '/content/drive/MyDrive/DL-Proyecto/Data/Test/Test/Rust/82add70df6ab2854.jpg' a mi programa...\n","Error en la predicción: [Errno 2] No such file or directory: '/tmp/18cc883fa48e3c3c224539e4b363a30f_/content/drive/MyDrive/DL-Proyecto/Data/Test/Test/Rust/82add70df6ab2854.jpg'\n","INFO:     127.0.0.1:47498 - \"POST /predict HTTP/1.1\" 500 Internal Server Error\n","Algo salió mal al enviar la foto o al recibir la respuesta: 500 Server Error: Internal Server Error for url: http://0.0.0.0:8000/predict\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ihJFegw8qlbZ"},"outputs":[],"source":["from src.nombre_paquete.preprocessing.preprocessing_prediction import preprocess_image_for_prediction\n","from src.nombre_paquete.evaluation.interpret_prediction import interpret_prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PDvKNMvyjMWV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753389045958,"user_tz":300,"elapsed":607,"user":{"displayName":"DANIEL TEJADA","userId":"09448008839633351094"}},"outputId":"a6c71f6e-81b1-4d2c-b39a-78539857dfaa"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Preprocesamiento de imagen ---\n","Imagen cargada desde: '/content/drive/MyDrive/DL-Proyecto/Data/Test/Test/Rust/82add70df6ab2854.jpg'.\n","Dimensiones originales de la imagen: (5184, 3456)\n","Dimensiones después de escalar (para el modelo): (180, 180)\n","Preprocesamiento: valores de píxeles normalizados a [0, 1].\n","Forma final del array de imagen: (1, 180, 180, 3)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step\n","\n","--- Resultados Detallados de la Predicción ---\n","  Saludable: 0.00000000 (0.0000%)\n","  Powdery: 0.00000000 (0.0000%)\n","  Rush: 1.00000000 (100.0000%)\n","\n","--- Clasificación ---\n","La imagen se clasifica como: Rush con una confianza del 100.00%.\n"]},{"output_type":"execute_result","data":{"text/plain":["{'saludable': 1.1505615278941714e-32,\n"," 'powdery': 2.6761094494548915e-29,\n"," 'rush': 1.0,\n"," 'predicted_class': 'rush',\n"," 'confidence': np.float32(100.0)}"]},"metadata":{},"execution_count":22}],"source":["img_array, __ = preprocess_image_for_prediction(img_path = '/content/drive/MyDrive/DL-Proyecto/Data/Test/Test/Rust/82add70df6ab2854.jpg')\n","prediccion =  model.predict(img_array)\n","results = interpret_prediction(prediccion)\n","results"]},{"cell_type":"markdown","source":["## Docs"],"metadata":{"id":"LIs44__MYiBR"}},{"cell_type":"code","source":["!mkdir -p /content/drive/MyDrive/Proyecto_MDS6/scripts/deployment"],"metadata":{"id":"CraRkqYbYhNv","executionInfo":{"status":"ok","timestamp":1753393733048,"user_tz":300,"elapsed":108,"user":{"displayName":"Daniel Tejada Hernandez","userId":"08292253613217380086"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["!copy /content/drive/MyDrive/DL-Proyecto/Entrega_5/deployment_notebook /content/drive/MyDrive/Proyecto_MDS6/"],"metadata":{"id":"KovriMCDaTVG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hBmkY_rDVq4x"},"source":["# Lineas utiles de GitHub"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A4EwOvQ3CkxW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753389249393,"user_tz":300,"elapsed":4222,"user":{"displayName":"DANIEL TEJADA","userId":"09448008839633351094"}},"outputId":"d0e40b06-3dae-4030-a8c8-e222d2a49642"},"outputs":[{"output_type":"stream","name":"stdout","text":["remote: Enumerating objects: 16, done.\u001b[K\n","remote: Counting objects:   6% (1/16)\u001b[K\rremote: Counting objects:  12% (2/16)\u001b[K\rremote: Counting objects:  18% (3/16)\u001b[K\rremote: Counting objects:  25% (4/16)\u001b[K\rremote: Counting objects:  31% (5/16)\u001b[K\rremote: Counting objects:  37% (6/16)\u001b[K\rremote: Counting objects:  43% (7/16)\u001b[K\rremote: Counting objects:  50% (8/16)\u001b[K\rremote: Counting objects:  56% (9/16)\u001b[K\rremote: Counting objects:  62% (10/16)\u001b[K\rremote: Counting objects:  68% (11/16)\u001b[K\rremote: Counting objects:  75% (12/16)\u001b[K\rremote: Counting objects:  81% (13/16)\u001b[K\rremote: Counting objects:  87% (14/16)\u001b[K\rremote: Counting objects:  93% (15/16)\u001b[K\rremote: Counting objects: 100% (16/16)\u001b[K\rremote: Counting objects: 100% (16/16), done.\u001b[K\n","remote: Compressing objects:  33% (1/3)\u001b[K\rremote: Compressing objects:  66% (2/3)\u001b[K\rremote: Compressing objects: 100% (3/3)\u001b[K\rremote: Compressing objects: 100% (3/3), done.\u001b[K\n","remote: Total 9 (delta 6), reused 9 (delta 6), pack-reused 0 (from 0)\u001b[K\n","Unpacking objects: 100% (9/9), 1.96 KiB | 2.00 KiB/s, done.\n","From https://github.com/Estefania5310/Proyecto_MDS6\n","   e068303..0939669  main       -> origin/main\n"]}],"source":["!git fetch origin"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WX5XWKQOCkqX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753389250844,"user_tz":300,"elapsed":86,"user":{"displayName":"DANIEL TEJADA","userId":"09448008839633351094"}},"outputId":"f2bf7c37-0a4a-4824-ee98-69b0ac9c1009"},"outputs":[{"output_type":"stream","name":"stdout","text":["Already on 'main'\n","Your branch and 'origin/main' have diverged,\n","and have 1 and 1 different commits each, respectively.\n","  (use \"git pull\" to merge the remote branch into yours)\n"]}],"source":["!git checkout main"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cXNvn6NbWKvZ"},"outputs":[],"source":["# Descartar cambios en un archivo en particular en el que se hicieron cambios en local\n","!git restore src/nombre_paquete/preprocessing/loading.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oOcoeWDtUMY5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753389275141,"user_tz":300,"elapsed":127,"user":{"displayName":"DANIEL TEJADA","userId":"09448008839633351094"}},"outputId":"4738e1d7-9cb9-41bf-d831-55acded4d240"},"outputs":[{"output_type":"stream","name":"stdout","text":["error: Merging is not possible because you have unmerged files.\n","\u001b[33mhint: Fix them up in the work tree, and then use 'git add/rm <file>'\u001b[m\n","\u001b[33mhint: as appropriate to mark resolution and make a commit.\u001b[m\n","fatal: Exiting because of an unresolved conflict.\n"]}],"source":["!git merge origin/main"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hMC592HiWhao"},"outputs":[],"source":["!git pull origin main"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C0Mh5hS998Z7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753389060194,"user_tz":300,"elapsed":736,"user":{"displayName":"DANIEL TEJADA","userId":"09448008839633351094"}},"outputId":"e040631f-b2cb-4451-9383-0169acfb6651"},"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\t\u001b[31msrc/nombre_paquete/evaluation/app2.py\u001b[m\n","\n","nothing added to commit but untracked files present (use \"git add\" to track)\n"]}],"source":["!git status"]},{"cell_type":"code","source":["!git add .\n","!git commit -m \"Se agrega la función que corre la app\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RdMbIwnXIdpU","executionInfo":{"status":"ok","timestamp":1753389317588,"user_tz":300,"elapsed":794,"user":{"displayName":"DANIEL TEJADA","userId":"09448008839633351094"}},"outputId":"af1c8b98-7af9-42b4-c7fd-ffde0d05ad2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[main f9ad59a] Se agrega la función que corre la app\n"]}]},{"cell_type":"code","source":["!git push https://{TOKEN_GITHUB}@github.com/Estefania5310/Proyecto_MDS6.git main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"51z-3AC6I4MR","executionInfo":{"status":"ok","timestamp":1753389327425,"user_tz":300,"elapsed":148,"user":{"displayName":"DANIEL TEJADA","userId":"09448008839633351094"}},"outputId":"da4575a0-054c-42ef-a6f5-3b62535fde2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enumerating objects: 21, done.\n","Counting objects:   4% (1/21)\rCounting objects:   9% (2/21)\rCounting objects:  14% (3/21)\rCounting objects:  19% (4/21)\rCounting objects:  23% (5/21)\rCounting objects:  28% (6/21)\rCounting objects:  33% (7/21)\rCounting objects:  38% (8/21)\rCounting objects:  42% (9/21)\rCounting objects:  47% (10/21)\rCounting objects:  52% (11/21)\rCounting objects:  57% (12/21)\rCounting objects:  61% (13/21)\rCounting objects:  66% (14/21)\rCounting objects:  71% (15/21)\rCounting objects:  76% (16/21)\rCounting objects:  80% (17/21)\rCounting objects:  85% (18/21)\rCounting objects:  90% (19/21)\rCounting objects:  95% (20/21)\rCounting objects: 100% (21/21)\rCounting objects: 100% (21/21), done.\n","Delta compression using up to 2 threads\n","Compressing objects: 100% (12/12), done.\n","Writing objects: 100% (12/12), 4.04 KiB | 229.00 KiB/s, done.\n","Total 12 (delta 7), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (7/7), completed with 5 local objects.\u001b[K\n","To https://github.com/Estefania5310/Proyecto_MDS6.git\n","   0939669..f9ad59a  main -> main\n"]}]},{"cell_type":"markdown","metadata":{"id":"gFCpIZQsj7tW"},"source":[]},{"cell_type":"markdown","metadata":{"id":"A1xJhSn9j7q8"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":289740,"status":"ok","timestamp":1753386612066,"user":{"displayName":"Daniel Tejada Hernandez","userId":"08292253613217380086"},"user_tz":300},"id":"R5l9cuK_1lzg","colab":{"base_uri":"https://localhost:8080/"},"outputId":"08ec362f-04cd-421a-cbe8-557c5b1779b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[32mINFO\u001b[0m:     Will watch for changes in these directories: ['/content/drive/My Drive/Proyecto_MDS6']\n","\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8000\u001b[0m (Press CTRL+C to quit)\n","\u001b[32mINFO\u001b[0m:     Started reloader process [\u001b[36m\u001b[1m116328\u001b[0m] using \u001b[36m\u001b[1mStatReload\u001b[0m\n","2025-07-24 19:45:26.788450: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1753386326.816549  116334 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1753386326.824173  116334 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-07-24 19:45:33.100007: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m116334\u001b[0m]\n","\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n","\u001b[32mINFO\u001b[0m:     Application startup complete.\n","\u001b[32mINFO\u001b[0m:     Shutting down\n","\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n","\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n","\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m116334\u001b[0m]\n","\u001b[32mINFO\u001b[0m:     Stopping reloader process [\u001b[36m\u001b[1m116328\u001b[0m]\n"]}],"source":["!uvicorn src.nombre_paquete.evaluation.app2:app --host 0.0.0.0 --port 8000 --reload"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}